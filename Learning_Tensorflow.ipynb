{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Learning_Tensorflow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "wYW-D-8qvmh2",
        "gbbA_jQCvrWO",
        "abamiVsGKGnX",
        "zWb0HAy2WqHb",
        "JBAxCJgbWkq5",
        "7oZjHmMKWe-V",
        "4owQxn4YRzmC",
        "0sbTAGXmnxHh",
        "obSyKVLqdFiQ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "LoEswpfT5-K7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model, save_model, load_model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, BatchNormalization, AveragePooling2D, Concatenate, GlobalAveragePooling2D, concatenate\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wYW-D-8qvmh2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Basics of Tensorflow"
      ]
    },
    {
      "metadata": {
        "id": "nowepOhgvllZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c354c270-529f-4290-9af1-7877b48536ea"
      },
      "cell_type": "code",
      "source": [
        "hello = tf.constant('Hello World')\n",
        "hello"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Const:0' shape=() dtype=string>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "_nfn_vIkv4iN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c328f5b2-b710-4069-ff73-0c43f0adb2bb"
      },
      "cell_type": "code",
      "source": [
        "x = tf.constant(100)\n",
        "x"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Const_1:0' shape=() dtype=int32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "7HamurE6v4k2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cmgFqmfxv4nX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9b0f92aa-2aa0-44ed-f8fc-5fd05cba17bf"
      },
      "cell_type": "code",
      "source": [
        "sess.run([hello, x])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[b'Hello World', 100]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "quwuPJsfv4p-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "ef5d6b6c-c157-43d3-edce-e3436ef4574a"
      },
      "cell_type": "code",
      "source": [
        "x = tf.constant(2)\n",
        "y = tf.constant(10)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    print(f\"Addition: {sess.run(x+y)}\")\n",
        "    print(f\"Subtraction: {sess.run(x-y)}\")\n",
        "    print(f\"Multiplication: {sess.run(x*y)}\")\n",
        "    print(f\"Division: {sess.run(x/y)}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Addition: 12\n",
            "Subtraction: -8\n",
            "Multiplication: 20\n",
            "Division: 0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pJKzPeb3v4sq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "eb18e984-4ea2-4842-fdf6-de415059687c"
      },
      "cell_type": "code",
      "source": [
        "x = tf.placeholder(tf.int32)\n",
        "y = tf.placeholder(tf.int32)\n",
        "\n",
        "add = tf.add(x, y)\n",
        "sub = tf.subtract(x, y)\n",
        "mul = tf.multiply(x, y)\n",
        "div = tf.divide(x, y)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    print(f\"Addition: {sess.run(add, feed_dict={x:2, y:10})}\")\n",
        "    print(f\"Subtraction: {sess.run(sub, feed_dict={x:2, y:10})}\")\n",
        "    print(f\"Multiplication: {sess.run(mul, feed_dict={x:2, y:10})}\")\n",
        "    print(f\"Division: {sess.run(div, feed_dict={x:2, y:10})}\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Addition: 12\n",
            "Subtraction: -8\n",
            "Multiplication: 20\n",
            "Division: 0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a9mIDas9v4v6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1fe39d90-eb5e-4e65-b4b9-96002a6f8bf5"
      },
      "cell_type": "code",
      "source": [
        "a = np.array([[5.0, 5.0]])\n",
        "b = np.array([[2.0], [2.0]])\n",
        "\n",
        "mat1 = tf.constant(a)\n",
        "mat2 = tf.constant(b)\n",
        "mat_mul = tf.matmul(mat1, mat2)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    print(f\"Matrix Multiplication: {sess.run(mat_mul)}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matrix Multiplication: [[20.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pjqOg5qTyKz9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "outputId": "a2df2ed2-9874-44ee-e58d-20bfa6459d26"
      },
      "cell_type": "code",
      "source": [
        "mnist = input_data.read_data_sets('mnist_data', one_hot=True)\n",
        "type(mnist)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting mnist_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting mnist_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting mnist_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting mnist_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.contrib.learn.python.learn.datasets.base.Datasets"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "h-nektRSyK29",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "ea9733c6-fb02-4aab-8f10-fff99c5db967"
      },
      "cell_type": "code",
      "source": [
        "print(mnist.train.images)\n",
        "print(mnist.train.num_examples)\n",
        "print(mnist.test.num_examples)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "55000\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-AV0hNi80_Xo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "6bce8651-e600-49da-d645-c5ae9175c2df"
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(mnist.train.images[1].reshape(28,28))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd58f66fbe0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "9-KgOXFi0_r4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b538c8a6-d8c4-4cf5-b666-3857d7aa9d5e"
      },
      "cell_type": "code",
      "source": [
        "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
        "W = tf.Variable(tf.zeros([784, 10]))\n",
        "b = tf.Variable(tf.zeros([10]))\n",
        "\n",
        "y_pred = tf.matmul(x, W) + b\n",
        "y_true = tf.placeholder(tf.float32, shape=[None, 10])\n",
        "\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_true, logits=y_pred))\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.5)\n",
        "train = optimizer.minimize(cost)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    \n",
        "    for step in range(1000):\n",
        "        batch_x, batch_y = mnist.train.next_batch(100)\n",
        "        sess.run(train, feed_dict={x:batch_x, y_true:batch_y})\n",
        "    \n",
        "    matches = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1))\n",
        "    acc = tf.reduce_mean(tf.cast(matches, tf.float32))\n",
        "    \n",
        "    print(f\"Accuracy: {sess.run(acc, feed_dict={x:mnist.test.images, y_true:mnist.test.labels})}\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9207000136375427\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gbbA_jQCvrWO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Working with MNIST dataset"
      ]
    },
    {
      "metadata": {
        "id": "Q4foHVYL8hRa",
        "colab_type": "code",
        "outputId": "2f1bdaa4-49da-4dbb-e728-a456e6d8a5be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train/255.0, x_test/255.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UO2DXW_j8hfh",
        "colab_type": "code",
        "outputId": "0f66d9ac-2f44-4bee-ab0f-214ec1eef976",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        }
      },
      "cell_type": "code",
      "source": [
        "img_size = x_train.shape[1]\n",
        "flat_img_size = img_size * img_size\n",
        "channels = 1\n",
        "num_classes = 10\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "plt.imshow(x_train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f78dc039940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "gFzUK7N9HIyS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# onehot_y_train = np.zeros((y_train.shape[0], num_classes))\n",
        "# onehot_y_test = np.zeros((y_test.shape[0], num_classes))\n",
        "\n",
        "# for i in range(y_train.shape[0]):\n",
        "#     onehot_y_train[i][y_train[i]] = 1\n",
        "    \n",
        "# for i in range(y_test.shape[0]):\n",
        "#     onehot_y_test[i][y_test[i]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y5WJveZh8hjp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_mod = np.zeros((x_train.shape[0], flat_img_size))\n",
        "test_mod = np.zeros((x_test.shape[0], flat_img_size))\n",
        "\n",
        "for i in range(x_train.shape[0]):\n",
        "    train_mod[i] = x_train[i].flatten()\n",
        "\n",
        "for i in range(x_test.shape[0]):\n",
        "    test_mod[i] = x_test[i].flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OFih-4sCWEUz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_batch(batch_size=128):\n",
        "    random_indices = np.random.randint(low=0, high=x_train.shape[0], size=batch_size)\n",
        "    random_img = np.array([train_mod[i] for i in random_indices], dtype=np.float32)\n",
        "    random_label = np.array([y_train[i]+1 for i in random_indices], dtype=np.int64).reshape(-1, 1)\n",
        "    return random_img, random_label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "abamiVsGKGnX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Native TF Code"
      ]
    },
    {
      "metadata": {
        "id": "h0Nv_4J9RQGX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 50\n",
        "\n",
        "x = tf.placeholder(tf.float32, [None, flat_img_size])\n",
        "y_true = tf.placeholder(tf.int64, [None, 1])\n",
        "\n",
        "weights = tf.Variable(tf.zeros([flat_img_size, 10]))\n",
        "biases = tf.Variable(tf.zeros([10]))\n",
        "\n",
        "logits = tf.add(tf.matmul(x, weights), biases)\n",
        "y_pred = tf.nn.softmax(logits)\n",
        "y_pred_cls = tf.argmax(y_pred, axis=1)\n",
        "\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,\n",
        "                                                                    labels=y_true))\n",
        "optimizer = tf.train.AdamOptimizer(0.01).minimize(cost)\n",
        "\n",
        "preds = tf.equal(y_pred_cls, y_true)\n",
        "accuracy = tf.reduce_mean(tf.cast(preds, tf.float32))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    for i in range(epochs):\n",
        "        for _ in range(int(x_train.shape[0] / batch_size)):\n",
        "            x_batch, y_batch = get_batch(batch_size)\n",
        "            _, acc, loss = sess.run([optimizer, accuracy, cost], {x: x_batch, y_true: y_batch})\n",
        "        \n",
        "        print(f\"Epoch {i} ===> Accuracy: {acc}, Loss: {loss}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Lil8OFIGI1W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Initialize Placeholders\n",
        "x = tf.placeholder(tf.float32, [None, 28, 28])\n",
        "y = tf.placeholder(tf.int32, [None, 1])\n",
        "\n",
        "# Flatten the Image data\n",
        "flat_img = tf.layers.flatten(x)\n",
        "\n",
        "# Feed to a Dense Layer\n",
        "logits = tf.contrib.layers.fully_connected(flat_img, 128, activation_fn=tf.nn.relu)\n",
        "\n",
        "# Define a Loss Function\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, \n",
        "                                                                logits=logits))\n",
        "\n",
        "# Define an Optimizer\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\n",
        "\n",
        "# Convert logits to Label Indices\n",
        "correct_pred = tf.argmax(logits, axis=1)\n",
        "\n",
        "# Define an Accuracy metric\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "tf.set_random_seed(42)\n",
        "epochs = 100\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    for i in range(epochs):\n",
        "        _, acc_value, loss_value = sess.run([optimizer, accuracy, loss], feed_dict={x: x_train, y: y_train.reshape(-1, 1)})\n",
        "        if i % 10 == 0:\n",
        "            print(f\"Epoch-{i} ===> Loss: {loss_value}, Accuracy: {acc_value}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zWb0HAy2WqHb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Keras Sequential API - ANN"
      ]
    },
    {
      "metadata": {
        "id": "CC1lFxiaSzW8",
        "colab_type": "code",
        "outputId": "a1f1b84e-ee0f-457d-88e6-3910a62c4f90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation=tf.nn.relu))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256, activation=tf.nn.relu))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation=tf.nn.relu))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation=tf.nn.softmax))\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=64, validation_split=0.3, verbose=0)\n",
        "results = model.evaluate(x_test, y_test)\n",
        "\n",
        "for i, j in zip(model.metrics_names, results):\n",
        "    print(f\"{i}: {j}\")\n",
        "\n",
        "save_model(model, 'ann_model')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 69us/sample - loss: 0.0786 - sparse_categorical_accuracy: 0.9783\n",
            "loss: 0.07856610854162427\n",
            "sparse_categorical_accuracy: 0.9782999753952026\n",
            "CPU times: user 53.4 s, sys: 5.64 s, total: 59 s\n",
            "Wall time: 44 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JBAxCJgbWkq5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Keras Sequential API - CNN"
      ]
    },
    {
      "metadata": {
        "id": "HoxddKeISzZh",
        "colab_type": "code",
        "outputId": "9663daf4-e5a1-45d5-c2f3-ed25de113ffc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=16, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), strides=2, padding='same'))\n",
        "\n",
        "model.add(Conv2D(filters=36, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), strides=2, padding='same'))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation=tf.nn.relu))\n",
        "model.add(Dense(10, activation=tf.nn.softmax))\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "model.fit(x_train.reshape(-1, 28, 28, 1), y_train, epochs=10, batch_size=64, validation_split=0.3, verbose=0)\n",
        "\n",
        "results = model.evaluate(x_test.reshape(-1, 28, 28, 1), y_test)\n",
        "for i, j in zip(model.metrics_names, results):\n",
        "    print(f\"{i}: {j}\")\n",
        "    \n",
        "save_model(model, 'cnn_model')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 90us/sample - loss: 0.0351 - sparse_categorical_accuracy: 0.9908\n",
            "loss: 0.03507390564493762\n",
            "sparse_categorical_accuracy: 0.9908000230789185\n",
            "CPU times: user 1min 5s, sys: 8.27 s, total: 1min 13s\n",
            "Wall time: 58.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Qhlm8JsUMjmT",
        "colab_type": "code",
        "outputId": "69acbc88-8f0a-4f8c-b177-afbe0d34b444",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ann_model  cnn_model  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7oZjHmMKWe-V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Functional Keras Model"
      ]
    },
    {
      "metadata": {
        "id": "AvTpl_kaSzcL",
        "colab_type": "code",
        "outputId": "cc703dde-bdc2-48b4-ea00-d21fd7bc3a66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "# The shape Input to this layer will not include the batch size, only the image size and the channel - in this case (28 x 28 x 1)\n",
        "inputs = Input(shape=(img_size, img_size, 1))\n",
        "\n",
        "conv1 = Conv2D(filters=16, kernel_size=5, strides=1, padding='same', data_format='channels_last', activation='relu', kernel_initializer='glorot_normal')(inputs)\n",
        "maxp1 = MaxPool2D(pool_size=2, strides=1, padding='valid')(conv1)\n",
        "\n",
        "conv2 = Conv2D(filters=36, kernel_size=5, strides=1, padding='same', data_format='channels_last', activation='relu', kernel_initializer='glorot_normal')(maxp1)\n",
        "maxp2 = MaxPool2D(pool_size=2, strides=1, padding='valid')(conv2)\n",
        "\n",
        "flat = Flatten()(maxp2)\n",
        "dense_out = Dense(256, activation='relu', kernel_initializer='he_normal')(flat)\n",
        "\n",
        "outputs = Dense(10, activation='softmax')(dense_out)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "model.fit(x_train.reshape(-1, img_size, img_size, channels), y_train, epochs=10, batch_size=64, validation_split=0.3, verbose=0)\n",
        "\n",
        "results = model.evaluate(x_test.reshape(-1, img_size, img_size, 1), y_test)\n",
        "for i, j in zip(model.metrics_names, results):\n",
        "    print(f\"{i}: {j}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 104us/sample - loss: 0.0411 - sparse_categorical_accuracy: 0.9906\n",
            "loss: 0.04111253512892363\n",
            "sparse_categorical_accuracy: 0.9905999898910522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4owQxn4YRzmC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Ensemble Learning - Neural Nets"
      ]
    },
    {
      "metadata": {
        "id": "9rv8zr_7Szoc",
        "colab_type": "code",
        "outputId": "dd7ff068-01e3-44fe-83d5-6719f7e279dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Basically the ANN & CNN models created and saved above. These models are loaded in memory and are used to predict the test data.\n",
        "# The final predictions are calculated using the mean of the two models. sklearn's Accuracy is used to evaluate the final accuracy of the ensemble.\n",
        "\n",
        "ensemble_preds = np.zeros(shape=(x_test.shape[0], num_classes))\n",
        "for model in ['ann_model', 'cnn_model']:\n",
        "    nw_model = load_model(model)\n",
        "    preds = nw_model.predict(x_test.reshape(-1, img_size, img_size, 1))\n",
        "    ensemble_preds += preds\n",
        "    \n",
        "ensemble_preds /= 2\n",
        "final_pred_cls = np.argmax(ensemble_preds, axis=1)\n",
        "print(f\"Ensemble Accuracy: {accuracy_score(y_test, final_pred_cls)}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n",
            "WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n",
            "Ensemble Accuracy: 0.9907\n",
            "CPU times: user 5.13 s, sys: 178 ms, total: 5.31 s\n",
            "Wall time: 4.98 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0sbTAGXmnxHh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CIFAR-10 Classification using CNN"
      ]
    },
    {
      "metadata": {
        "id": "EfAtf8-ZSzrz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cifar = tf.keras.datasets.cifar10\n",
        "(x_train, y_train), (x_test, y_test) = cifar.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HSiKHQXQGI5w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# print(plt.imshow(x_train[1]))\n",
        "# print(x_train.shape)\n",
        "\n",
        "num_classes = 10\n",
        "img_size = 32\n",
        "channels = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZDS1kUfkGI3r",
        "colab_type": "code",
        "outputId": "2700f9ea-af73-463e-9259-38730c175d9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "cell_type": "code",
      "source": [
        "# Model building\n",
        "\n",
        "inputs = Input(shape=(img_size, img_size, channels))\n",
        "x = inputs\n",
        "\n",
        "x = Conv2D(filters=32, kernel_size=3, strides=2, padding='same', activation='relu', kernel_initializer='he_normal')(x)\n",
        "x = MaxPool2D(pool_size=2, strides=1, padding='valid')(x)\n",
        "\n",
        "x = Conv2D(filters=64, kernel_size=3, strides=2, padding='same', activation='relu', kernel_initializer='he_normal')(x)\n",
        "x = MaxPool2D(pool_size=2, strides=1, padding='valid')(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "\n",
        "x = Dense(units=256, activation='relu', kernel_initializer='he_normal')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "x = Dense(units=64, activation='relu', kernel_initializer='he_normal')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "outputs = Dense(units=10, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 8, 8, 64)          18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 256)               803072    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 839,562\n",
            "Trainable params: 839,562\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "O46VseCEGJCA",
        "colab_type": "code",
        "outputId": "d718e5f3-814e-49b4-feb0-e8af587ce3ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1327
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "datagen.fit(x_train)\n",
        "\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=64, seed=42), \n",
        "                    epochs=25, validation_data=(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "10000/10000 [==============================] - 1s 100us/sample - loss: 0.9319 - sparse_categorical_accuracy: 0.6759\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 1.1389 - sparse_categorical_accuracy: 0.6109 - val_loss: 0.9318 - val_sparse_categorical_accuracy: 0.6759\n",
            "Epoch 2/25\n",
            "10000/10000 [==============================] - 1s 102us/sample - loss: 0.9128 - sparse_categorical_accuracy: 0.6809\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 1.1216 - sparse_categorical_accuracy: 0.6172 - val_loss: 0.9130 - val_sparse_categorical_accuracy: 0.6809\n",
            "Epoch 3/25\n",
            "10000/10000 [==============================] - 1s 99us/sample - loss: 0.8992 - sparse_categorical_accuracy: 0.6848\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 1.1021 - sparse_categorical_accuracy: 0.6250 - val_loss: 0.9003 - val_sparse_categorical_accuracy: 0.6848\n",
            "Epoch 4/25\n",
            "10000/10000 [==============================] - 1s 101us/sample - loss: 0.9656 - sparse_categorical_accuracy: 0.6650\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 1.0899 - sparse_categorical_accuracy: 0.6310 - val_loss: 0.9662 - val_sparse_categorical_accuracy: 0.6650\n",
            "Epoch 5/25\n",
            "10000/10000 [==============================] - 1s 99us/sample - loss: 0.9508 - sparse_categorical_accuracy: 0.6713\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 1.0843 - sparse_categorical_accuracy: 0.6311 - val_loss: 0.9517 - val_sparse_categorical_accuracy: 0.6713\n",
            "Epoch 6/25\n",
            "10000/10000 [==============================] - 1s 101us/sample - loss: 0.8638 - sparse_categorical_accuracy: 0.6991\n",
            "782/782 [==============================] - 29s 38ms/step - loss: 1.0733 - sparse_categorical_accuracy: 0.6395 - val_loss: 0.8642 - val_sparse_categorical_accuracy: 0.6991\n",
            "Epoch 7/25\n",
            "10000/10000 [==============================] - 1s 97us/sample - loss: 0.8789 - sparse_categorical_accuracy: 0.6931\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 1.0534 - sparse_categorical_accuracy: 0.6462 - val_loss: 0.8797 - val_sparse_categorical_accuracy: 0.6931\n",
            "Epoch 8/25\n",
            "10000/10000 [==============================] - 1s 101us/sample - loss: 0.8664 - sparse_categorical_accuracy: 0.6968\n",
            "782/782 [==============================] - 29s 38ms/step - loss: 1.0458 - sparse_categorical_accuracy: 0.6485 - val_loss: 0.8676 - val_sparse_categorical_accuracy: 0.6968\n",
            "Epoch 9/25\n",
            "10000/10000 [==============================] - 1s 99us/sample - loss: 0.8541 - sparse_categorical_accuracy: 0.7020\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 1.0411 - sparse_categorical_accuracy: 0.6501 - val_loss: 0.8551 - val_sparse_categorical_accuracy: 0.7020\n",
            "Epoch 10/25\n",
            "10000/10000 [==============================] - 1s 99us/sample - loss: 0.8700 - sparse_categorical_accuracy: 0.7035\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 1.0317 - sparse_categorical_accuracy: 0.6549 - val_loss: 0.8711 - val_sparse_categorical_accuracy: 0.7035\n",
            "Epoch 11/25\n",
            "10000/10000 [==============================] - 1s 103us/sample - loss: 0.8571 - sparse_categorical_accuracy: 0.7001\n",
            "782/782 [==============================] - 29s 38ms/step - loss: 1.0212 - sparse_categorical_accuracy: 0.6575 - val_loss: 0.8579 - val_sparse_categorical_accuracy: 0.7001\n",
            "Epoch 12/25\n",
            "10000/10000 [==============================] - 1s 99us/sample - loss: 0.8924 - sparse_categorical_accuracy: 0.6884\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 1.0171 - sparse_categorical_accuracy: 0.6619 - val_loss: 0.8934 - val_sparse_categorical_accuracy: 0.6884\n",
            "Epoch 13/25\n",
            "10000/10000 [==============================] - 1s 98us/sample - loss: 0.8748 - sparse_categorical_accuracy: 0.6985\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 1.0065 - sparse_categorical_accuracy: 0.6634 - val_loss: 0.8754 - val_sparse_categorical_accuracy: 0.6985\n",
            "Epoch 14/25\n",
            "10000/10000 [==============================] - 1s 99us/sample - loss: 0.9269 - sparse_categorical_accuracy: 0.6768\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 1.0062 - sparse_categorical_accuracy: 0.6616 - val_loss: 0.9282 - val_sparse_categorical_accuracy: 0.6768\n",
            "Epoch 15/25\n",
            "10000/10000 [==============================] - 1s 95us/sample - loss: 0.8478 - sparse_categorical_accuracy: 0.7076\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 0.9988 - sparse_categorical_accuracy: 0.6646 - val_loss: 0.8491 - val_sparse_categorical_accuracy: 0.7076\n",
            "Epoch 16/25\n",
            "10000/10000 [==============================] - 1s 100us/sample - loss: 0.7799 - sparse_categorical_accuracy: 0.7326\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 0.9811 - sparse_categorical_accuracy: 0.6704 - val_loss: 0.7809 - val_sparse_categorical_accuracy: 0.7326\n",
            "Epoch 17/25\n",
            "10000/10000 [==============================] - 1s 102us/sample - loss: 0.8104 - sparse_categorical_accuracy: 0.7233\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 0.9830 - sparse_categorical_accuracy: 0.6721 - val_loss: 0.8108 - val_sparse_categorical_accuracy: 0.7233\n",
            "Epoch 18/25\n",
            "10000/10000 [==============================] - 1s 99us/sample - loss: 0.8225 - sparse_categorical_accuracy: 0.7201\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 0.9831 - sparse_categorical_accuracy: 0.6725 - val_loss: 0.8221 - val_sparse_categorical_accuracy: 0.7201\n",
            "Epoch 19/25\n",
            "10000/10000 [==============================] - 1s 101us/sample - loss: 0.8199 - sparse_categorical_accuracy: 0.7194\n",
            "782/782 [==============================] - 29s 38ms/step - loss: 0.9776 - sparse_categorical_accuracy: 0.6743 - val_loss: 0.8200 - val_sparse_categorical_accuracy: 0.7194\n",
            "Epoch 20/25\n",
            "10000/10000 [==============================] - 1s 102us/sample - loss: 0.8262 - sparse_categorical_accuracy: 0.7134\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 0.9669 - sparse_categorical_accuracy: 0.6782 - val_loss: 0.8265 - val_sparse_categorical_accuracy: 0.7134\n",
            "Epoch 21/25\n",
            "10000/10000 [==============================] - 1s 100us/sample - loss: 0.8354 - sparse_categorical_accuracy: 0.7067\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 0.9586 - sparse_categorical_accuracy: 0.6787 - val_loss: 0.8354 - val_sparse_categorical_accuracy: 0.7067\n",
            "Epoch 22/25\n",
            "10000/10000 [==============================] - 1s 102us/sample - loss: 0.8134 - sparse_categorical_accuracy: 0.7213\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 0.9521 - sparse_categorical_accuracy: 0.6800 - val_loss: 0.8142 - val_sparse_categorical_accuracy: 0.7213\n",
            "Epoch 23/25\n",
            "10000/10000 [==============================] - 1s 95us/sample - loss: 0.8084 - sparse_categorical_accuracy: 0.7217\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 0.9539 - sparse_categorical_accuracy: 0.6825 - val_loss: 0.8088 - val_sparse_categorical_accuracy: 0.7217\n",
            "Epoch 24/25\n",
            "10000/10000 [==============================] - 1s 95us/sample - loss: 0.7924 - sparse_categorical_accuracy: 0.7279\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 0.9520 - sparse_categorical_accuracy: 0.6812 - val_loss: 0.7928 - val_sparse_categorical_accuracy: 0.7279\n",
            "Epoch 25/25\n",
            "10000/10000 [==============================] - 1s 99us/sample - loss: 0.7808 - sparse_categorical_accuracy: 0.7343\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 0.9449 - sparse_categorical_accuracy: 0.6857 - val_loss: 0.7809 - val_sparse_categorical_accuracy: 0.7343\n",
            "CPU times: user 14min 41s, sys: 30.6 s, total: 15min 12s\n",
            "Wall time: 12min 11s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f38bbd14400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "obSyKVLqdFiQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Building an Inception Network using Functional API\n",
        "[Inception V3 Research Paper](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Szegedy_Rethinking_the_Inception_CVPR_2016_paper.pdf)\n",
        "\n",
        "![Inception N/W Architecture](https://www.google.com/url?sa=i&source=images&cd=&cad=rja&uact=8&ved=2ahUKEwj90sPrkeDgAhWQeysKHZ3tBw4QjRx6BAgBEAU&url=https%3A%2F%2Fstackoverflow.com%2Fquestions%2F41473397%2Fhow-to-obtain-information-on-tensorflow-architecture&psig=AOvVaw2d_5hJEc5I5C-ts1io4Hjw&ust=1551500200524165)"
      ]
    },
    {
      "metadata": {
        "id": "U8s5r7xGGJEM",
        "colab_type": "code",
        "outputId": "fc1d77eb-9f96-4194-f6fd-32b3b0bc4803",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7644
        }
      },
      "cell_type": "code",
      "source": [
        "inputs = Input(shape=(299, 299, 3))\n",
        "\n",
        "x = Conv2D(filters=32, kernel_size=3, strides=2, padding='valid', activation='relu')(inputs)\n",
        "x = BatchNormalization(axis=3, scale=False)(x)    # axis=3 --> Refers to Channels - 3rd position in shape\n",
        "\n",
        "x = Conv2D(filters=32, kernel_size=3, strides=1, padding='valid', activation='relu')(x)\n",
        "x = BatchNormalization(axis=3, scale=False)(x)\n",
        "\n",
        "x = Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu')(x)\n",
        "x = BatchNormalization(axis=3, scale=False)(x)\n",
        "\n",
        "x = MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
        "\n",
        "x = Conv2D(filters=80, kernel_size=3, strides=1, padding='valid', activation='relu')(x)\n",
        "x = BatchNormalization(axis=3, scale=False)(x)\n",
        "\n",
        "x = Conv2D(filters=192, kernel_size=3, strides=2, padding='valid', activation='relu')(x)\n",
        "x = BatchNormalization(axis=3, scale=False)(x)\n",
        "\n",
        "x = Conv2D(filters=288, kernel_size=3, strides=1, padding='valid', activation='relu')(x)\n",
        "x = BatchNormalization(axis=3, scale=False)(x)\n",
        "\n",
        "x = MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
        "\n",
        "# 3 x Inception Layer (Fig. 5 in Paper)\n",
        "for _ in range(3):\n",
        "    branch_1x1 = Conv2D(filters=64, kernel_size=1, strides=1, padding='same', activation='relu')(x)\n",
        "    branch_1x1 = BatchNormalization(axis=3, scale=False)(branch_1x1)\n",
        "\n",
        "    branch_3x3 = Conv2D(filters=48, kernel_size=1, strides=1, padding='same', activation='relu')(x)\n",
        "    branch_3x3 = BatchNormalization(axis=3, scale=False)(branch_3x3)\n",
        "    branch_3x3 = Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu')(branch_3x3)\n",
        "    branch_3x3 = BatchNormalization(axis=3, scale=False)(branch_3x3)\n",
        "\n",
        "    branch_5x5 = Conv2D(filters=64, kernel_size=1, strides=1, padding='same', activation='relu')(x)\n",
        "    branch_5x5 = BatchNormalization(axis=3, scale=False)(branch_5x5)\n",
        "    branch_5x5 = Conv2D(filters=96, kernel_size=3, strides=1, padding='same', activation='relu')(branch_5x5)\n",
        "    branch_5x5 = BatchNormalization(axis=3, scale=False)(branch_5x5)\n",
        "    branch_5x5 = Conv2D(filters=96, kernel_size=3, strides=1, padding='same', activation='relu')(branch_5x5)\n",
        "    branch_5x5 = BatchNormalization(axis=3, scale=False)(branch_5x5)\n",
        "\n",
        "    branch_pool = AveragePooling2D(pool_size=3, strides=1, padding='same')(x)\n",
        "    branch_pool = Conv2D(filters=64, kernel_size=1, strides=1, padding='same', activation='relu')(branch_pool)\n",
        "\n",
        "    x = concatenate([branch_1x1, branch_3x3, branch_5x5, branch_pool], axis=3)\n",
        "    \n",
        "# 5 x Inception Layer (Fig. 6 in Paper)\n",
        "for _ in range(5):\n",
        "    branch_1x1 = Conv2D(filters=320, kernel_size=1, strides=1, padding='same', activation='relu')(x)\n",
        "    branch_1x1 = BatchNormalization(axis=3, scale=False)(branch_1x1)\n",
        "\n",
        "    branch_7x7 = Conv2D(filters=128, kernel_size=(1, 1), strides=1, padding='same', activation='relu')(x)\n",
        "    branch_7x7 = BatchNormalization(axis=3, scale=False)(branch_7x7)\n",
        "    branch_7x7 = Conv2D(filters=128, kernel_size=(1, 7), strides=1, padding='same', activation='relu')(branch_7x7)\n",
        "    branch_7x7 = BatchNormalization(axis=3, scale=False)(branch_7x7)\n",
        "    branch_7x7 = Conv2D(filters=320, kernel_size=(7, 1), strides=1, padding='same', activation='relu')(branch_7x7)\n",
        "    branch_7x7 = BatchNormalization(axis=3, scale=False)(branch_7x7)\n",
        "    \n",
        "    branch_7x7_dbl = Conv2D(filters=128, kernel_size=(1, 1), strides=1, padding='same', activation='relu')(x)\n",
        "    branch_7x7_dbl = BatchNormalization(axis=3, scale=False)(branch_7x7_dbl)\n",
        "    branch_7x7_dbl = Conv2D(filters=128, kernel_size=(1, 7), strides=1, padding='same', activation='relu')(branch_7x7_dbl)\n",
        "    branch_7x7_dbl = BatchNormalization(axis=3, scale=False)(branch_7x7_dbl)\n",
        "    branch_7x7_dbl = Conv2D(filters=128, kernel_size=(7, 1), strides=1, padding='same', activation='relu')(branch_7x7_dbl)\n",
        "    branch_7x7_dbl = BatchNormalization(axis=3, scale=False)(branch_7x7_dbl)\n",
        "    branch_7x7_dbl = Conv2D(filters=128, kernel_size=(1, 7), strides=1, padding='same', activation='relu')(branch_7x7_dbl)\n",
        "    branch_7x7_dbl = BatchNormalization(axis=3, scale=False)(branch_7x7_dbl)\n",
        "    branch_7x7_dbl = Conv2D(filters=320, kernel_size=(7, 1), strides=1, padding='same', activation='relu')(branch_7x7_dbl)\n",
        "    branch_7x7_dbl = BatchNormalization(axis=3, scale=False)(branch_7x7_dbl)\n",
        "\n",
        "    branch_pool = AveragePooling2D(pool_size=3, strides=1, padding='same')(x)\n",
        "    branch_pool = Conv2D(filters=320, kernel_size=1, strides=1, padding='same', activation='relu')(branch_pool)\n",
        "\n",
        "    x = concatenate([branch_1x1, branch_7x7, branch_7x7_dbl, branch_pool], axis=3)\n",
        "\n",
        "outputs_2 = x    # Auxilliary Output\n",
        "\n",
        "# 2 x Inception Layer (Fig. 7 in Paper)\n",
        "for _ in range(2):\n",
        "    branch_1x1 = Conv2D(filters=324, kernel_size=1, strides=1, padding='same', activation='relu')(x)\n",
        "    branch_1x1 = BatchNormalization(axis=3, scale=False)(branch_1x1)\n",
        "\n",
        "    branch_1 = Conv2D(filters=160, kernel_size=(1, 1), strides=1, padding='same', activation='relu')(x)\n",
        "    branch_1 = BatchNormalization(axis=3, scale=False)(branch_1)\n",
        "    \n",
        "    branch_2 = Conv2D(filters=350, kernel_size=(1, 3), strides=1, padding='same', activation='relu')(branch_1)\n",
        "    branch_2 = BatchNormalization(axis=3, scale=False)(branch_2)\n",
        "    branch_3 = Conv2D(filters=350, kernel_size=(3, 1), strides=1, padding='same', activation='relu')(branch_1)\n",
        "    branch_3 = BatchNormalization(axis=3, scale=False)(branch_3)\n",
        "    \n",
        "    branch_4 = Conv2D(filters=160, kernel_size=(1, 1), strides=1, padding='same', activation='relu')(x)\n",
        "    branch_4 = BatchNormalization(axis=3, scale=False)(branch_4)\n",
        "    branch_5 = Conv2D(filters=160, kernel_size=(3, 3), strides=1, padding='same', activation='relu')(branch_4)\n",
        "    branch_5 = BatchNormalization(axis=3, scale=False)(branch_5)\n",
        "    \n",
        "    branch_6 = Conv2D(filters=350, kernel_size=(1, 3), strides=1, padding='same', activation='relu')(branch_5)\n",
        "    branch_6 = BatchNormalization(axis=3, scale=False)(branch_6)\n",
        "    branch_7 = Conv2D(filters=350, kernel_size=(3, 1), strides=1, padding='same', activation='relu')(branch_5)\n",
        "    branch_7 = BatchNormalization(axis=3, scale=False)(branch_7)\n",
        "    \n",
        "    branch_pool = AveragePooling2D(pool_size=3, strides=1, padding='same')(x)\n",
        "    branch_pool = Conv2D(filters=324, kernel_size=1, strides=1, padding='same', activation='relu')(branch_pool)\n",
        "\n",
        "    x = concatenate([branch_1x1, branch_2, branch_3, branch_6, branch_7, branch_pool], axis=3)\n",
        "    \n",
        "x = MaxPool2D(pool_size=(8, 8), strides=2, padding='same')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(units=1000, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=[outputs_2, x])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "print(model.summary())\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_348 (Conv2D)             (None, 149, 149, 32) 896         input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_312 (Bat (None, 149, 149, 32) 96          conv2d_348[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_349 (Conv2D)             (None, 147, 147, 32) 9248        batch_normalization_v1_312[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_313 (Bat (None, 147, 147, 32) 96          conv2d_349[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_350 (Conv2D)             (None, 147, 147, 64) 18496       batch_normalization_v1_313[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_314 (Bat (None, 147, 147, 64) 192         conv2d_350[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling2D) (None, 74, 74, 64)   0           batch_normalization_v1_314[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_351 (Conv2D)             (None, 72, 72, 80)   46160       max_pooling2d_15[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_315 (Bat (None, 72, 72, 80)   240         conv2d_351[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_352 (Conv2D)             (None, 35, 35, 192)  138432      batch_normalization_v1_315[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_316 (Bat (None, 35, 35, 192)  576         conv2d_352[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_353 (Conv2D)             (None, 33, 33, 288)  497952      batch_normalization_v1_316[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_317 (Bat (None, 33, 33, 288)  864         conv2d_353[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling2D) (None, 17, 17, 288)  0           batch_normalization_v1_317[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_357 (Conv2D)             (None, 17, 17, 64)   18496       max_pooling2d_16[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_321 (Bat (None, 17, 17, 64)   192         conv2d_357[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_355 (Conv2D)             (None, 17, 17, 48)   13872       max_pooling2d_16[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_358 (Conv2D)             (None, 17, 17, 96)   55392       batch_normalization_v1_321[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_319 (Bat (None, 17, 17, 48)   144         conv2d_355[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_322 (Bat (None, 17, 17, 96)   288         conv2d_358[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_354 (Conv2D)             (None, 17, 17, 64)   18496       max_pooling2d_16[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_356 (Conv2D)             (None, 17, 17, 64)   27712       batch_normalization_v1_319[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_359 (Conv2D)             (None, 17, 17, 96)   83040       batch_normalization_v1_322[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_36 (AveragePo (None, 17, 17, 288)  0           max_pooling2d_16[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_318 (Bat (None, 17, 17, 64)   192         conv2d_354[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_320 (Bat (None, 17, 17, 64)   192         conv2d_356[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_323 (Bat (None, 17, 17, 96)   288         conv2d_359[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_360 (Conv2D)             (None, 17, 17, 64)   18496       average_pooling2d_36[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_36 (Concatenate)    (None, 17, 17, 288)  0           batch_normalization_v1_318[0][0] \n",
            "                                                                 batch_normalization_v1_320[0][0] \n",
            "                                                                 batch_normalization_v1_323[0][0] \n",
            "                                                                 conv2d_360[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_364 (Conv2D)             (None, 17, 17, 64)   18496       concatenate_36[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_327 (Bat (None, 17, 17, 64)   192         conv2d_364[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_362 (Conv2D)             (None, 17, 17, 48)   13872       concatenate_36[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_365 (Conv2D)             (None, 17, 17, 96)   55392       batch_normalization_v1_327[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_325 (Bat (None, 17, 17, 48)   144         conv2d_362[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_328 (Bat (None, 17, 17, 96)   288         conv2d_365[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_361 (Conv2D)             (None, 17, 17, 64)   18496       concatenate_36[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_363 (Conv2D)             (None, 17, 17, 64)   27712       batch_normalization_v1_325[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_366 (Conv2D)             (None, 17, 17, 96)   83040       batch_normalization_v1_328[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_37 (AveragePo (None, 17, 17, 288)  0           concatenate_36[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_324 (Bat (None, 17, 17, 64)   192         conv2d_361[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_326 (Bat (None, 17, 17, 64)   192         conv2d_363[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_329 (Bat (None, 17, 17, 96)   288         conv2d_366[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_367 (Conv2D)             (None, 17, 17, 64)   18496       average_pooling2d_37[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_37 (Concatenate)    (None, 17, 17, 288)  0           batch_normalization_v1_324[0][0] \n",
            "                                                                 batch_normalization_v1_326[0][0] \n",
            "                                                                 batch_normalization_v1_329[0][0] \n",
            "                                                                 conv2d_367[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_371 (Conv2D)             (None, 17, 17, 64)   18496       concatenate_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_333 (Bat (None, 17, 17, 64)   192         conv2d_371[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_369 (Conv2D)             (None, 17, 17, 48)   13872       concatenate_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_372 (Conv2D)             (None, 17, 17, 96)   55392       batch_normalization_v1_333[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_331 (Bat (None, 17, 17, 48)   144         conv2d_369[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_334 (Bat (None, 17, 17, 96)   288         conv2d_372[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_368 (Conv2D)             (None, 17, 17, 64)   18496       concatenate_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_370 (Conv2D)             (None, 17, 17, 64)   27712       batch_normalization_v1_331[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_373 (Conv2D)             (None, 17, 17, 96)   83040       batch_normalization_v1_334[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_38 (AveragePo (None, 17, 17, 288)  0           concatenate_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_330 (Bat (None, 17, 17, 64)   192         conv2d_368[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_332 (Bat (None, 17, 17, 64)   192         conv2d_370[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_335 (Bat (None, 17, 17, 96)   288         conv2d_373[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_374 (Conv2D)             (None, 17, 17, 64)   18496       average_pooling2d_38[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_38 (Concatenate)    (None, 17, 17, 288)  0           batch_normalization_v1_330[0][0] \n",
            "                                                                 batch_normalization_v1_332[0][0] \n",
            "                                                                 batch_normalization_v1_335[0][0] \n",
            "                                                                 conv2d_374[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_379 (Conv2D)             (None, 17, 17, 128)  36992       concatenate_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_340 (Bat (None, 17, 17, 128)  384         conv2d_379[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_380 (Conv2D)             (None, 17, 17, 128)  114816      batch_normalization_v1_340[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_341 (Bat (None, 17, 17, 128)  384         conv2d_380[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_376 (Conv2D)             (None, 17, 17, 128)  36992       concatenate_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_381 (Conv2D)             (None, 17, 17, 128)  114816      batch_normalization_v1_341[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_337 (Bat (None, 17, 17, 128)  384         conv2d_376[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_342 (Bat (None, 17, 17, 128)  384         conv2d_381[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_377 (Conv2D)             (None, 17, 17, 128)  114816      batch_normalization_v1_337[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_382 (Conv2D)             (None, 17, 17, 128)  114816      batch_normalization_v1_342[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_338 (Bat (None, 17, 17, 128)  384         conv2d_377[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_343 (Bat (None, 17, 17, 128)  384         conv2d_382[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_375 (Conv2D)             (None, 17, 17, 320)  92480       concatenate_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_378 (Conv2D)             (None, 17, 17, 320)  287040      batch_normalization_v1_338[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_383 (Conv2D)             (None, 17, 17, 320)  287040      batch_normalization_v1_343[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_39 (AveragePo (None, 17, 17, 288)  0           concatenate_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_336 (Bat (None, 17, 17, 320)  960         conv2d_375[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_339 (Bat (None, 17, 17, 320)  960         conv2d_378[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_344 (Bat (None, 17, 17, 320)  960         conv2d_383[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_384 (Conv2D)             (None, 17, 17, 320)  92480       average_pooling2d_39[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_39 (Concatenate)    (None, 17, 17, 1280) 0           batch_normalization_v1_336[0][0] \n",
            "                                                                 batch_normalization_v1_339[0][0] \n",
            "                                                                 batch_normalization_v1_344[0][0] \n",
            "                                                                 conv2d_384[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_389 (Conv2D)             (None, 17, 17, 128)  163968      concatenate_39[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_349 (Bat (None, 17, 17, 128)  384         conv2d_389[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_390 (Conv2D)             (None, 17, 17, 128)  114816      batch_normalization_v1_349[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_350 (Bat (None, 17, 17, 128)  384         conv2d_390[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_386 (Conv2D)             (None, 17, 17, 128)  163968      concatenate_39[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_391 (Conv2D)             (None, 17, 17, 128)  114816      batch_normalization_v1_350[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_346 (Bat (None, 17, 17, 128)  384         conv2d_386[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_351 (Bat (None, 17, 17, 128)  384         conv2d_391[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_387 (Conv2D)             (None, 17, 17, 128)  114816      batch_normalization_v1_346[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_392 (Conv2D)             (None, 17, 17, 128)  114816      batch_normalization_v1_351[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_347 (Bat (None, 17, 17, 128)  384         conv2d_387[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_352 (Bat (None, 17, 17, 128)  384         conv2d_392[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_385 (Conv2D)             (None, 17, 17, 320)  409920      concatenate_39[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_388 (Conv2D)             (None, 17, 17, 320)  287040      batch_normalization_v1_347[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_393 (Conv2D)             (None, 17, 17, 320)  287040      batch_normalization_v1_352[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_40 (AveragePo (None, 17, 17, 1280) 0           concatenate_39[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_345 (Bat (None, 17, 17, 320)  960         conv2d_385[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_348 (Bat (None, 17, 17, 320)  960         conv2d_388[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_353 (Bat (None, 17, 17, 320)  960         conv2d_393[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_394 (Conv2D)             (None, 17, 17, 320)  409920      average_pooling2d_40[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_40 (Concatenate)    (None, 17, 17, 1280) 0           batch_normalization_v1_345[0][0] \n",
            "                                                                 batch_normalization_v1_348[0][0] \n",
            "                                                                 batch_normalization_v1_353[0][0] \n",
            "                                                                 conv2d_394[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_399 (Conv2D)             (None, 17, 17, 128)  163968      concatenate_40[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_358 (Bat (None, 17, 17, 128)  384         conv2d_399[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_400 (Conv2D)             (None, 17, 17, 128)  114816      batch_normalization_v1_358[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_359 (Bat (None, 17, 17, 128)  384         conv2d_400[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_396 (Conv2D)             (None, 17, 17, 128)  163968      concatenate_40[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_401 (Conv2D)             (None, 17, 17, 128)  114816      batch_normalization_v1_359[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_355 (Bat (None, 17, 17, 128)  384         conv2d_396[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_360 (Bat (None, 17, 17, 128)  384         conv2d_401[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_397 (Conv2D)             (None, 17, 17, 128)  114816      batch_normalization_v1_355[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_402 (Conv2D)             (None, 17, 17, 128)  114816      batch_normalization_v1_360[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_356 (Bat (None, 17, 17, 128)  384         conv2d_397[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_361 (Bat (None, 17, 17, 128)  384         conv2d_402[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_395 (Conv2D)             (None, 17, 17, 320)  409920      concatenate_40[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_398 (Conv2D)             (None, 17, 17, 320)  287040      batch_normalization_v1_356[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_403 (Conv2D)             (None, 17, 17, 320)  287040      batch_normalization_v1_361[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_41 (AveragePo (None, 17, 17, 1280) 0           concatenate_40[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_354 (Bat (None, 17, 17, 320)  960         conv2d_395[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_357 (Bat (None, 17, 17, 320)  960         conv2d_398[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_362 (Bat (None, 17, 17, 320)  960         conv2d_403[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_404 (Conv2D)             (None, 17, 17, 320)  409920      average_pooling2d_41[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_41 (Concatenate)    (None, 17, 17, 1280) 0           batch_normalization_v1_354[0][0] \n",
            "                                                                 batch_normalization_v1_357[0][0] \n",
            "                                                                 batch_normalization_v1_362[0][0] \n",
            "                                                                 conv2d_404[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_409 (Conv2D)             (None, 17, 17, 128)  163968      concatenate_41[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_367 (Bat (None, 17, 17, 128)  384         conv2d_409[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_410 (Conv2D)             (None, 17, 17, 128)  114816      batch_normalization_v1_367[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_368 (Bat (None, 17, 17, 128)  384         conv2d_410[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_406 (Conv2D)             (None, 17, 17, 128)  163968      concatenate_41[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_411 (Conv2D)             (None, 17, 17, 128)  114816      batch_normalization_v1_368[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_364 (Bat (None, 17, 17, 128)  384         conv2d_406[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_369 (Bat (None, 17, 17, 128)  384         conv2d_411[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_407 (Conv2D)             (None, 17, 17, 128)  114816      batch_normalization_v1_364[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_412 (Conv2D)             (None, 17, 17, 128)  114816      batch_normalization_v1_369[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_365 (Bat (None, 17, 17, 128)  384         conv2d_407[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_370 (Bat (None, 17, 17, 128)  384         conv2d_412[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_405 (Conv2D)             (None, 17, 17, 320)  409920      concatenate_41[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_408 (Conv2D)             (None, 17, 17, 320)  287040      batch_normalization_v1_365[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_413 (Conv2D)             (None, 17, 17, 320)  287040      batch_normalization_v1_370[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_42 (AveragePo (None, 17, 17, 1280) 0           concatenate_41[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_363 (Bat (None, 17, 17, 320)  960         conv2d_405[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_366 (Bat (None, 17, 17, 320)  960         conv2d_408[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_371 (Bat (None, 17, 17, 320)  960         conv2d_413[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_414 (Conv2D)             (None, 17, 17, 320)  409920      average_pooling2d_42[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_42 (Concatenate)    (None, 17, 17, 1280) 0           batch_normalization_v1_363[0][0] \n",
            "                                                                 batch_normalization_v1_366[0][0] \n",
            "                                                                 batch_normalization_v1_371[0][0] \n",
            "                                                                 conv2d_414[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_419 (Conv2D)             (None, 17, 17, 128)  163968      concatenate_42[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_376 (Bat (None, 17, 17, 128)  384         conv2d_419[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_420 (Conv2D)             (None, 17, 17, 128)  114816      batch_normalization_v1_376[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_377 (Bat (None, 17, 17, 128)  384         conv2d_420[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_416 (Conv2D)             (None, 17, 17, 128)  163968      concatenate_42[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_421 (Conv2D)             (None, 17, 17, 128)  114816      batch_normalization_v1_377[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_373 (Bat (None, 17, 17, 128)  384         conv2d_416[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_378 (Bat (None, 17, 17, 128)  384         conv2d_421[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_417 (Conv2D)             (None, 17, 17, 128)  114816      batch_normalization_v1_373[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_422 (Conv2D)             (None, 17, 17, 128)  114816      batch_normalization_v1_378[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_374 (Bat (None, 17, 17, 128)  384         conv2d_417[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_379 (Bat (None, 17, 17, 128)  384         conv2d_422[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_415 (Conv2D)             (None, 17, 17, 320)  409920      concatenate_42[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_418 (Conv2D)             (None, 17, 17, 320)  287040      batch_normalization_v1_374[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_423 (Conv2D)             (None, 17, 17, 320)  287040      batch_normalization_v1_379[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_43 (AveragePo (None, 17, 17, 1280) 0           concatenate_42[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_372 (Bat (None, 17, 17, 320)  960         conv2d_415[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_375 (Bat (None, 17, 17, 320)  960         conv2d_418[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_380 (Bat (None, 17, 17, 320)  960         conv2d_423[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_424 (Conv2D)             (None, 17, 17, 320)  409920      average_pooling2d_43[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_43 (Concatenate)    (None, 17, 17, 1280) 0           batch_normalization_v1_372[0][0] \n",
            "                                                                 batch_normalization_v1_375[0][0] \n",
            "                                                                 batch_normalization_v1_380[0][0] \n",
            "                                                                 conv2d_424[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_429 (Conv2D)             (None, 17, 17, 160)  204960      concatenate_43[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_385 (Bat (None, 17, 17, 160)  480         conv2d_429[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_426 (Conv2D)             (None, 17, 17, 160)  204960      concatenate_43[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_430 (Conv2D)             (None, 17, 17, 160)  230560      batch_normalization_v1_385[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_382 (Bat (None, 17, 17, 160)  480         conv2d_426[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_386 (Bat (None, 17, 17, 160)  480         conv2d_430[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_425 (Conv2D)             (None, 17, 17, 324)  415044      concatenate_43[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_427 (Conv2D)             (None, 17, 17, 350)  168350      batch_normalization_v1_382[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_428 (Conv2D)             (None, 17, 17, 350)  168350      batch_normalization_v1_382[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_431 (Conv2D)             (None, 17, 17, 350)  168350      batch_normalization_v1_386[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_432 (Conv2D)             (None, 17, 17, 350)  168350      batch_normalization_v1_386[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_44 (AveragePo (None, 17, 17, 1280) 0           concatenate_43[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_381 (Bat (None, 17, 17, 324)  972         conv2d_425[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_383 (Bat (None, 17, 17, 350)  1050        conv2d_427[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_384 (Bat (None, 17, 17, 350)  1050        conv2d_428[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_387 (Bat (None, 17, 17, 350)  1050        conv2d_431[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_388 (Bat (None, 17, 17, 350)  1050        conv2d_432[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_433 (Conv2D)             (None, 17, 17, 324)  415044      average_pooling2d_44[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_44 (Concatenate)    (None, 17, 17, 2048) 0           batch_normalization_v1_381[0][0] \n",
            "                                                                 batch_normalization_v1_383[0][0] \n",
            "                                                                 batch_normalization_v1_384[0][0] \n",
            "                                                                 batch_normalization_v1_387[0][0] \n",
            "                                                                 batch_normalization_v1_388[0][0] \n",
            "                                                                 conv2d_433[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_438 (Conv2D)             (None, 17, 17, 160)  327840      concatenate_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_393 (Bat (None, 17, 17, 160)  480         conv2d_438[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_435 (Conv2D)             (None, 17, 17, 160)  327840      concatenate_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_439 (Conv2D)             (None, 17, 17, 160)  230560      batch_normalization_v1_393[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_390 (Bat (None, 17, 17, 160)  480         conv2d_435[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_394 (Bat (None, 17, 17, 160)  480         conv2d_439[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_434 (Conv2D)             (None, 17, 17, 324)  663876      concatenate_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_436 (Conv2D)             (None, 17, 17, 350)  168350      batch_normalization_v1_390[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_437 (Conv2D)             (None, 17, 17, 350)  168350      batch_normalization_v1_390[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_440 (Conv2D)             (None, 17, 17, 350)  168350      batch_normalization_v1_394[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_441 (Conv2D)             (None, 17, 17, 350)  168350      batch_normalization_v1_394[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_45 (AveragePo (None, 17, 17, 2048) 0           concatenate_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_389 (Bat (None, 17, 17, 324)  972         conv2d_434[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_391 (Bat (None, 17, 17, 350)  1050        conv2d_436[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_392 (Bat (None, 17, 17, 350)  1050        conv2d_437[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_395 (Bat (None, 17, 17, 350)  1050        conv2d_440[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_396 (Bat (None, 17, 17, 350)  1050        conv2d_441[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_442 (Conv2D)             (None, 17, 17, 324)  663876      average_pooling2d_45[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_45 (Concatenate)    (None, 17, 17, 2048) 0           batch_normalization_v1_389[0][0] \n",
            "                                                                 batch_normalization_v1_391[0][0] \n",
            "                                                                 batch_normalization_v1_392[0][0] \n",
            "                                                                 batch_normalization_v1_395[0][0] \n",
            "                                                                 batch_normalization_v1_396[0][0] \n",
            "                                                                 conv2d_442[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling2D) (None, 9, 9, 2048)   0           concatenate_45[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 9, 9, 2048)   0           max_pooling2d_17[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 9, 9, 1000)   2049000     dropout_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 18,559,920\n",
            "Trainable params: 18,529,856\n",
            "Non-trainable params: 30,064\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P-IzTNHjbNoe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning using Inception V3 model"
      ]
    },
    {
      "metadata": {
        "id": "dhxaxKFBGJHE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fD6v9VxRGJJ-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QALC5XyaGJPX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CbKgfpMWGJRy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R3EMlAOjGJVF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}